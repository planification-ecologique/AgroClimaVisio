from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List
from datetime import date, datetime
from pathlib import Path
import random
import math
import os

from models import (
    VariableType, ExperimentType, VARIABLES_INFO, VariableInfo
)
from datasets import (
    AVAILABLE_DATASETS, get_datasets_for_variables, 
    get_datasets_for_experiment, get_datasets_for_period
)
from points_config import get_all_points

app = FastAPI(title="AgroClimaVisio API", version="1.0.0")

# CORS middleware pour permettre les requ√™tes depuis le frontend
# Permet les origines depuis les variables d'environnement ou localhost par d√©faut
allowed_origins = os.getenv("CORS_ORIGINS", "http://localhost:5173").split(",")
app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# Mod√®les de donn√©es
class PeriodRequest(BaseModel):
    start_date: str  # Format: "YYYY-MM-DD"
    end_date: str
    year: int  # 2020, 2030, 2040, 2050


class ClimateParameters(BaseModel):
    min_rainfall: Optional[float] = None  # mm
    min_rainfall_probability: Optional[float] = None  # 0-1
    degree_days_threshold: Optional[float] = None  # Degr√©s-jours
    degree_days_probability: Optional[float] = None
    max_hot_days_30: Optional[int] = None  # Jours > 30¬∞C
    max_hot_days_35: Optional[int] = None  # Jours > 35¬∞C
    hot_days_probability: Optional[float] = None
    consecutive_dry_days: Optional[int] = None  # Jours cons√©cutifs sans pluie
    extreme_rainfall_threshold: Optional[float] = None  # mm en 30 min
    max_7day_rainfall: Optional[float] = None  # mm sur 7 jours
    non_workable_days_threshold: Optional[int] = None  # Jours avec pluie > 2mm


class MapRequest(BaseModel):
    period: PeriodRequest
    map_type: str  # "potential", "drought", "excess_water", "extremes", "heat_waves"
    parameters: ClimateParameters


@app.get("/")
async def root():
    return {"message": "AgroClimaVisio API", "version": "1.0.0"}


@app.on_event("startup")
async def startup_event():
    """Initialise le loader DuckDB au d√©marrage de l'application"""
    print("üöÄ D√©marrage de l'application...")
    # Initialiser DuckDB en arri√®re-plan pour ne pas bloquer le d√©marrage
    import asyncio
    async def init_duckdb():
        try:
            loader = get_duckdb_loader()
            if loader:
                print("‚úÖ Loader DuckDB initialis√© avec succ√®s au d√©marrage")
            else:
                print("‚ö†Ô∏è  Loader DuckDB non disponible au d√©marrage (sera initialis√© √† la premi√®re requ√™te)")
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur lors de l'initialisation au d√©marrage: {e}")
            print("‚ö†Ô∏è  L'application continuera sans DuckDB (sera initialis√© √† la premi√®re requ√™te)")
    
    # Lancer l'initialisation en arri√®re-plan sans attendre
    asyncio.create_task(init_duckdb())
    print("‚úÖ Application d√©marr√©e (initialisation DuckDB en cours en arri√®re-plan)")


@app.get("/health")
async def health():
    return {"status": "ok"}


@app.get("/debug/db")
async def debug_db():
    """Endpoint de debug pour v√©rifier l'√©tat de la base de donn√©es"""
    global _duckdb_init_error
    debug_info = {
        "current_directory": os.getcwd(),
        "file_parent": str(Path(__file__).parent),
        "duckdb_path_env": os.getenv("DUCKDB_PATH"),
        "possible_paths": [],
        "found_path": None,
        "loader_available": _duckdb_loader is not None,
        "init_error": _duckdb_init_error
    }
    
    # Liste des chemins possibles
    possible_paths = []
    if os.getenv("DUCKDB_PATH"):
        possible_paths.append(Path(os.getenv("DUCKDB_PATH")) / "climate_data.duckdb")
    possible_paths.append(Path(__file__).parent / "data" / "climate_data.duckdb")
    possible_paths.append(Path("/app/backend/data/climate_data.duckdb"))
    possible_paths.append(Path("backend/data/climate_data.duckdb"))
    possible_paths.append(Path("data/climate_data.duckdb"))
    
    for path in possible_paths:
        exists = path.exists()
        debug_info["possible_paths"].append({
            "path": str(path),
            "exists": exists,
            "is_file": path.is_file() if exists else False,
            "size_mb": round(path.stat().st_size / (1024 * 1024), 2) if exists and path.is_file() else None
        })
        if exists and debug_info["found_path"] is None:
            debug_info["found_path"] = str(path)
    
    return debug_info


# Initialiser le chargeur DuckDB une seule fois au d√©marrage
_duckdb_loader = None
_duckdb_init_error = None

def get_duckdb_loader():
    """Obtient ou cr√©e le chargeur DuckDB"""
    global _duckdb_loader, _duckdb_init_error
    if _duckdb_loader is None:
        try:
            from duckdb_loader import DuckDBClimateLoader
            
            # Liste des chemins possibles √† v√©rifier (dans l'ordre de priorit√©)
            possible_paths = []
            
            # 1. Variable d'environnement DUCKDB_PATH (Volume Railway)
            if os.getenv("DUCKDB_PATH"):
                possible_paths.append(Path(os.getenv("DUCKDB_PATH")) / "climate_data.duckdb")
            
            # 2. backend/data/ (d√©veloppement local et Railway par d√©faut)
            possible_paths.append(Path(__file__).parent / "data" / "climate_data.duckdb")
            
            # 3. Chemin absolu /app/backend/data/ (Railway)
            possible_paths.append(Path("/app/backend/data/climate_data.duckdb"))
            
            # 4. Chemin relatif depuis le r√©pertoire courant
            possible_paths.append(Path("backend/data/climate_data.duckdb"))
            possible_paths.append(Path("data/climate_data.duckdb"))
            
            # Chercher le premier chemin qui existe
            db_path = None
            for path in possible_paths:
                if path.exists():
                    db_path = path
                    print(f"‚úÖ Base de donn√©es DuckDB trouv√©e: {db_path}")
                    break
            
            if db_path is None:
                print("‚ö†Ô∏è  Base de donn√©es DuckDB non trouv√©e. Chemins v√©rifi√©s:")
                for path in possible_paths:
                    print(f"   - {path} (existe: {path.exists()})")
                print(f"   R√©pertoire courant: {os.getcwd()}")
                print(f"   __file__ parent: {Path(__file__).parent}")
                print(f"   DUCKDB_PATH env: {os.getenv('DUCKDB_PATH')}")
            else:
                try:
                    print(f"üîÑ Initialisation du loader DuckDB avec: {db_path}")
                    _duckdb_loader = DuckDBClimateLoader(db_path=str(db_path))
                    print("‚úÖ Loader DuckDB initialis√© avec succ√®s")
                    _duckdb_init_error = None  # R√©initialiser l'erreur en cas de succ√®s
                except Exception as loader_error:
                    _duckdb_init_error = str(loader_error)
                    print(f"‚ùå Erreur lors de l'initialisation du loader DuckDB: {loader_error}")
                    import traceback
                    traceback.print_exc()
                    # Ne pas lever l'exception, on veut que l'API d√©marre m√™me sans DB
        except Exception as e:
            _duckdb_init_error = str(e)
            print(f"‚ö†Ô∏è  Erreur lors de l'initialisation de DuckDB: {e}")
            import traceback
            traceback.print_exc()
            # Ne pas lever l'exception ici, on veut que l'API d√©marre m√™me sans DB
            # Le loader sera None et les endpoints retourneront une erreur appropri√©e
    return _duckdb_loader


class MonthlyChartRequest(BaseModel):
    """Requ√™te pour obtenir les donn√©es climatiques mensuelles"""
    start_date: str  # Format: "YYYY-MM-DD"
    end_date: str    # Format: "YYYY-MM-DD"
    experiment: Optional[str] = "ssp370"  # Par d√©faut ssp370
    variable: str = "pr"  # Variable climatique: "pr" (pr√©cipitations) ou "tas" (temp√©rature)
    gcm: Optional[str] = None  # Si None, utilise tous les GCM disponibles
    rcm: Optional[str] = None  # Si None, utilise tous les RCM disponibles
    cities: Optional[List[str]] = None  # Liste des villes √† inclure (ex: ["Chartres", "Rennes"])
    members: Optional[List[str]] = None  # Liste des membres d'ensemble (ex: ["r1", "r2"])


@app.post("/api/charts/monthly")
async def get_monthly_chart_data(request: MonthlyChartRequest):
    """
    R√©cup√®re les donn√©es climatiques mensuelles pour les points repr√©sentatifs
    sur une p√©riode donn√©e.
    
    Variables support√©es:
    - "pr": Pr√©cipitations (somme mensuelle en mm)
    - "tas": Temp√©rature (moyenne mensuelle en ¬∞C)
    
    Retourne les donn√©es agr√©g√©es par mois pour chaque point.
    """
    loader = get_duckdb_loader()
    if loader is None:
        return {
            "error": "Base de donn√©es DuckDB non disponible",
            "points": []
        }
    
    try:
        from models import VariableType, ExperimentType
        
        # Convertir les dates (g√©rer les cas o√π c'est d√©j√† un objet date ou une cha√Æne)
        if isinstance(request.start_date, str):
            start_date = datetime.strptime(request.start_date, "%Y-%m-%d").date()
        elif isinstance(request.start_date, date):
            start_date = request.start_date
        else:
            start_date = datetime.fromisoformat(str(request.start_date)).date()
        
        if isinstance(request.end_date, str):
            end_date = datetime.strptime(request.end_date, "%Y-%m-%d").date()
        elif isinstance(request.end_date, date):
            end_date = request.end_date
        else:
            end_date = datetime.fromisoformat(str(request.end_date)).date()
        
        # Convertir l'exp√©rience
        experiment_map = {
            "historical": ExperimentType.HISTORICAL,
            "ssp370": ExperimentType.SSP370,
            "ssp585": ExperimentType.SSP585,
            "ssp245": ExperimentType.SSP245,
            "ssp126": ExperimentType.SSP126,
        }
        experiment = experiment_map.get(request.experiment.lower(), ExperimentType.SSP370)
        
        # Points repr√©sentatifs depuis la configuration centralis√©e
        all_points = get_all_points(format="dict")
        
        # Filtrer les points par villes si sp√©cifi√©es
        if request.cities and len(request.cities) > 0:
            # Convertir en minuscules pour comparaison insensible √† la casse
            cities_lower = [c.lower() for c in request.cities]
            all_points = [p for p in all_points if p['name'].lower() in cities_lower]
        
        if not all_points:
            return {
                "error": "Aucun point trouv√© pour les villes s√©lectionn√©es",
                "points": []
            }
        
        # Valider la variable
        if request.variable not in ['pr', 'tas']:
            return {
                "error": f"Variable non support√©e: {request.variable}. Utilisez 'pr' ou 'tas'.",
                "points": []
            }
        
        # Construire la requ√™te SQL selon la variable
        # IMPORTANT: Grouper par gcm/rcm/member pour √©viter le double comptage
        # Filtrer uniquement les donn√©es EMUL
        if request.variable == 'pr':
            # Pr√©cipitations: somme mensuelle (convertir kg/m¬≤/s en mm)
            aggregation = "SUM(value * 86400) as monthly_total"
        else:  # tas
            # Temp√©rature: moyenne mensuelle (convertir Kelvin en Celsius)
            # Les donn√©es sont stock√©es en Kelvin, on soustrait 273.15 pour obtenir ¬∞C
            aggregation = "AVG(value - 273.15) as monthly_avg"
        
        query = f"""
            SELECT 
                lat,
                lon,
                gcm,
                rcm,
                member,
                EXTRACT(YEAR FROM time) as year,
                EXTRACT(MONTH FROM time) as month,
                {aggregation},
                COUNT(*) as days_count
            FROM climate_data
            WHERE variable = ?
              AND experiment = ?
              AND time >= ?
              AND time <= ?
              AND (rcm LIKE '%EMUL%' OR rcm LIKE '%emul%' OR rcm = 'CNRM-ALADIN63-EMUL')
        """
        
        params = [request.variable, experiment.value, start_date, end_date]
        
        # Ajouter filtres GCM/RCM si sp√©cifi√©s
        if request.gcm:
            query += " AND gcm = ?"
            params.append(request.gcm)
        
        if request.rcm:
            query += " AND rcm = ?"
            params.append(request.rcm)
        
        # Filtrer par membres d'ensemble si sp√©cifi√©s
        if request.members and len(request.members) > 0:
            # Cr√©er une liste de placeholders pour les membres
            member_placeholders = ','.join(['?' for _ in request.members])
            query += f" AND member IN ({member_placeholders})"
            params.extend(request.members)
        
        # Filtrer pour les points sp√©cifiques (avec tol√©rance de 0.1 degr√©)
        # Optimisation: utiliser une condition combin√©e pour meilleure performance
        point_conditions = []
        for point in all_points:
            point_conditions.append(f"(ABS(lat - {point['lat']}) < 0.1 AND ABS(lon - {point['lon']}) < 0.1)")
        
        query += f" AND ({' OR '.join(point_conditions)})"
        
        query += """
            GROUP BY lat, lon, gcm, rcm, member, year, month
            ORDER BY lat, lon, gcm, rcm, member, year, month
        """
        
        result_df = loader.conn.execute(query, params).df()
        
        if result_df.empty:
            return {
                "error": "Aucune donn√©e trouv√©e pour cette p√©riode",
                "points": []
            }
        
        # Convertir en format JSON pour le frontend
        # Grouper par point ET par gcm/rcm pour √©viter le double comptage
        # Si plusieurs gcm/rcm existent pour le m√™me point/mois, on les garde s√©par√©s
        data_by_point_gcm_rcm = {}
        
        for _, row in result_df.iterrows():
            # Trouver le point le plus proche
            point_key = None
            min_dist = float('inf')
            for point in all_points:
                dist = abs(row['lat'] - point['lat']) + abs(row['lon'] - point['lon'])
                if dist < min_dist:
                    min_dist = dist
                    point_key = point['name']
            
            # Cl√© unique: point + gcm + rcm + member pour √©viter le double comptage
            gcm = str(row['gcm'])
            rcm = str(row['rcm'])
            member = str(row['member'])
            unique_key = f"{point_key}_{gcm}_{rcm}_{member}"
            
            if unique_key not in data_by_point_gcm_rcm:
                data_by_point_gcm_rcm[unique_key] = {
                    "name": point_key,
                    "lat": float(row['lat']),
                    "lon": float(row['lon']),
                    "gcm": gcm,
                    "rcm": rcm,
                    "member": member,
                    "data": []
                }
            
            # R√©cup√©rer la valeur selon la variable
            if request.variable == 'pr':
                # Pr√©cipitations: valeur d√©j√† convertie en mm
                value = float(row['monthly_total'])
            else:  # tas
                # Temp√©rature: moyenne en ¬∞C
                value = float(row['monthly_avg'])
            
            data_by_point_gcm_rcm[unique_key]["data"].append({
                "year": int(row['year']),
                "month": int(row['month']),
                "date": f"{int(row['year'])}-{int(row['month']):02d}",
                "value": round(value, 2),
                "days_count": int(row['days_count'])
            })
        
        # Convertir en liste et trier
        # Chaque combinaison point/gcm/rcm/member aura sa propre s√©rie temporelle
        result_data = list(data_by_point_gcm_rcm.values())
        for point_data in result_data:
            point_data["data"].sort(key=lambda x: (x["year"], x["month"]))
            # Ajouter le nom avec gcm/rcm/member pour identification dans le frontend
            point_data["name"] = f"{point_data['name']} ({point_data['gcm']}/{point_data['rcm']}/{point_data['member']})"
        
        return {
            "start_date": request.start_date,
            "end_date": request.end_date,
            "experiment": request.experiment,
            "variable": request.variable,
            "points": result_data
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {
            "error": str(e),
            "points": []
        }


@app.get("/api/charts/options")
async def get_charts_options():
    """
    Retourne les options disponibles pour les filtres (villes et membres d'ensemble).
    """
    loader = get_duckdb_loader()
    if loader is None:
        return {
            "error": "Base de donn√©es DuckDB non disponible",
            "cities": [],
            "members": []
        }
    
    try:
        # R√©cup√©rer toutes les villes disponibles depuis la configuration
        all_points = get_all_points(format="dict")
        cities = [{"name": p["name"], "region": p["region"]} for p in all_points]
        
        # R√©cup√©rer les membres d'ensemble disponibles depuis la base de donn√©es
        # (pour toutes les variables, pas seulement pr)
        members_df = loader.conn.execute("""
            SELECT DISTINCT member
            FROM climate_data
            WHERE (rcm LIKE '%EMUL%' OR rcm LIKE '%emul%' OR rcm = 'CNRM-ALADIN63-EMUL')
            ORDER BY member
        """).df()
        
        members = members_df['member'].tolist() if not members_df.empty else []
        
        return {
            "cities": cities,
            "members": members
        }
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {
            "error": str(e),
            "cities": [],
            "members": []
        }


def generate_mock_geojson(map_type: str, center_lon: float = 1.4437, center_lat: float = 43.6047):
    """
    G√©n√®re des donn√©es GeoJSON mock√©es autour d'un point central (Toulouse par d√©faut).
    Cr√©e une grille de polygones avec des valeurs simul√©es selon le type de carte.
    """
    features = []
    grid_size = 5  # 5x5 grille
    cell_size = 0.1  # Taille de chaque cellule en degr√©s
    
    # Valeurs de base selon le type de carte
    base_values = {
        "potential": {"min": 30, "max": 90, "unit": "%"},
        "drought": {"min": 0, "max": 45, "unit": "jours"},
        "excess_water": {"min": 0, "max": 80, "unit": "mm"},
        "extremes": {"min": 0, "max": 25, "unit": "√©v√©nements"},
        "heat_waves": {"min": 0, "max": 20, "unit": "jours"}
    }
    
    config = base_values.get(map_type, {"min": 0, "max": 100, "unit": ""})
    
    for i in range(grid_size):
        for j in range(grid_size):
            # Position de la cellule
            lon_offset = (i - grid_size / 2) * cell_size
            lat_offset = (j - grid_size / 2) * cell_size
            
            # Coordonn√©es du centre de la cellule
            cell_lon = center_lon + lon_offset
            cell_lat = center_lat + lat_offset
            
            # Valeur simul√©e avec variation spatiale
            # Cr√©er un pattern r√©aliste avec variation graduelle
            distance_from_center = math.sqrt(lon_offset**2 + lat_offset**2)
            base_value = config["min"] + (config["max"] - config["min"]) * (1 - distance_from_center / (grid_size * cell_size / 2))
            value = base_value + random.uniform(-10, 10)
            value = max(config["min"], min(config["max"], value))  # Clamp entre min et max
            
            # Cr√©er un polygone carr√© pour la cellule
            half_cell = cell_size / 2
            coordinates = [[
                [cell_lon - half_cell, cell_lat - half_cell],
                [cell_lon + half_cell, cell_lat - half_cell],
                [cell_lon + half_cell, cell_lat + half_cell],
                [cell_lon - half_cell, cell_lat + half_cell],
                [cell_lon - half_cell, cell_lat - half_cell]
            ]]
            
            feature = {
                "type": "Feature",
                "geometry": {
                    "type": "Polygon",
                    "coordinates": coordinates
                },
                "properties": {
                    "value": round(value, 1),
                    "cell_id": f"{i}_{j}"
                }
            }
            features.append(feature)
    
    return {
        "type": "FeatureCollection",
        "features": features
    }


@app.post("/api/maps/data")
async def get_map_data(request: MapRequest):
    """
    Endpoint pour r√©cup√©rer les donn√©es de carte selon les param√®tres.
    Essaie de charger les donn√©es r√©elles, sinon retourne des donn√©es mock√©es.
    """
    import os
    from datetime import datetime
    from climate_data import ClimateDataLoader
    from indicators import AgroClimateIndicators
    
    # Essayer de charger les donn√©es r√©elles
    # Chercher dans plusieurs emplacements possibles
    possible_dirs = [
        os.getenv("CLIMATE_DATA_DIR"),  # Variable d'environnement (priorit√©)
        os.path.join(os.path.dirname(__file__), "data"),  # backend/data/
        os.path.join(os.path.dirname(os.path.dirname(__file__)), "data"),  # ./data/ √† la racine
    ]
    
    # V√©rifier que le r√©pertoire existe ET contient des fichiers .nc
    use_real_data = False
    data_directory = None
    
    for dir_path in possible_dirs:
        if not dir_path:
            continue
        if os.path.exists(dir_path):
            nc_files = list(Path(dir_path).glob("*.nc"))
            print(f"üîç V√©rification: {dir_path} -> {len(nc_files)} fichiers .nc")
            if len(nc_files) > 0:
                data_directory = dir_path
                use_real_data = True
                import logging
                logger = logging.getLogger(__name__)
                logger.info(f"‚úÖ Donn√©es r√©elles trouv√©es: {len(nc_files)} fichier(s) dans {data_directory}")
                print(f"‚úÖ Donn√©es r√©elles trouv√©es: {len(nc_files)} fichier(s) dans {data_directory}")
                break
    
    if not use_real_data:
        import logging
        logger = logging.getLogger(__name__)
        logger.warning("‚ö†Ô∏è  Aucun fichier .nc trouv√©. Utilisation des donn√©es mock√©es.")
        logger.info("üí° Placez vos fichiers .nc dans backend/data/ ou ./data/")
        print("‚ö†Ô∏è  Aucun fichier .nc trouv√©. Utilisation des donn√©es mock√©es.")
        print(f"üí° R√©pertoires v√©rifi√©s: {possible_dirs}")
    
    if use_real_data:
        try:
            import logging
            logger = logging.getLogger(__name__)
            logger.info(f"üîÑ Tentative de chargement des donn√©es r√©elles depuis {data_directory}")
            print(f"üîÑ Tentative de chargement des donn√©es r√©elles depuis {data_directory}")
            
            loader = ClimateDataLoader(data_directory)
            indicators = AgroClimateIndicators(loader)
            
            # Convertir les dates et ajuster √† l'ann√©e de la requ√™te
            # Les dates de la requ√™te peuvent √™tre dans une ann√©e diff√©rente (ex: 2024)
            # mais on veut les donn√©es pour l'ann√©e sp√©cifi√©e (ex: 2020)
            original_start = datetime.strptime(request.period.start_date, "%Y-%m-%d").date()
            original_end = datetime.strptime(request.period.end_date, "%Y-%m-%d").date()
            
            # Ajuster les dates √† l'ann√©e de la requ√™te
            start_date = original_start.replace(year=request.period.year)
            end_date = original_end.replace(year=request.period.year)
            
            logger.info(f"üìÖ Dates ajust√©es: {start_date} √† {end_date} (ann√©e: {request.period.year})")
            print(f"üìÖ Dates ajust√©es: {start_date} √† {end_date} (ann√©e: {request.period.year})")
            
            # D√©terminer le sc√©nario selon l'ann√©e
            if request.period.year <= 2014:
                experiment = ExperimentType.HISTORICAL
            else:
                experiment = ExperimentType.SSP370  # Par d√©faut
            
            logger.info(f"üî¨ Sc√©nario s√©lectionn√©: {experiment.value} pour l'ann√©e {request.period.year}")
            print(f"üî¨ Sc√©nario s√©lectionn√©: {experiment.value} pour l'ann√©e {request.period.year}")
            
            # Utiliser un mod√®le par d√©faut (peut √™tre param√©trable plus tard)
            gcm = "CNRM-ESM2-1"
            rcm = "CNRM-ALADIN64E1"
            member = "r1"
            
            # Calculer l'indicateur selon le type de carte
            if request.map_type == "potential":
                result = indicators.calculate_potential_indicator(
                    experiment, gcm, rcm, start_date, end_date,
                    request.parameters.min_rainfall or 80,
                    request.parameters.min_rainfall_probability or 0.8,
                    request.parameters.degree_days_threshold or 500,
                    request.parameters.max_hot_days_30 or 10,
                    member
                )
            elif request.map_type == "drought":
                result = indicators.calculate_drought_risk(
                    experiment, gcm, rcm, start_date, end_date,
                    request.parameters.consecutive_dry_days or 10,
                    member
                )
            elif request.map_type == "excess_water":
                result = indicators.calculate_excess_water_risk(
                    experiment, gcm, rcm, start_date, end_date,
                    request.parameters.max_7day_rainfall or 40,
                    request.parameters.non_workable_days_threshold or 7,
                    member
                )
            elif request.map_type == "heat_waves":
                result = indicators.calculate_heat_waves(
                    experiment, gcm, rcm, start_date, end_date,
                    request.parameters.max_hot_days_35 or 5,
                    member
                )
            else:
                result = None
                print(f"‚ö†Ô∏è  Type de carte non g√©r√©: {request.map_type}")
            
            if result is not None:
                print(f"‚úÖ R√©sultat calcul√© avec succ√®s pour {request.map_type}")
                # Convertir en GeoJSON
                geojson_data = indicators.dataarray_to_geojson(result)
                
                # Calculer min/max pour la l√©gende
                values = [f["properties"]["value"] for f in geojson_data["features"]]
                legend = {
                    "min": min(values) if values else 0,
                    "max": max(values) if values else 100,
                    "unit": "%" if request.map_type == "potential" else "jours" if request.map_type in ["drought", "heat_waves"] else "mm"
                }
                
                return {
                    "map_type": request.map_type,
                    "period": request.period.dict(),
                    "parameters": request.parameters.dict(),
                    "data": geojson_data,
                    "legend": legend,
                    "data_source": "real"
                }
            else:
                print(f"‚ö†Ô∏è  R√©sultat None pour {request.map_type}, basculement vers mock")
        except Exception as e:
            # En cas d'erreur, utiliser les donn√©es mock√©es
            import logging
            import traceback
            logger = logging.getLogger(__name__)
            logger.error(f"‚ùå Erreur lors du chargement des donn√©es r√©elles: {e}")
            logger.debug(traceback.format_exc())
            logger.info("üîÑ Basculement vers les donn√©es mock√©es")
            print(f"‚ùå Erreur lors du chargement des donn√©es r√©elles: {e}")
            print(traceback.format_exc())
            print("üîÑ Basculement vers les donn√©es mock√©es")
    
    # G√©n√©rer des donn√©es mock√©es (fallback)
    mock_data = generate_mock_geojson(request.map_type)
    
    # D√©terminer la l√©gende selon le type de carte
    legend_configs = {
        "potential": {"min": 0, "max": 100, "unit": "%"},
        "drought": {"min": 0, "max": 50, "unit": "jours"},
        "excess_water": {"min": 0, "max": 100, "unit": "mm"},
        "extremes": {"min": 0, "max": 30, "unit": "√©v√©nements"},
        "heat_waves": {"min": 0, "max": 25, "unit": "jours"}
    }
    
    legend = legend_configs.get(request.map_type, {"min": 0, "max": 100, "unit": ""})
    
    return {
        "map_type": request.map_type,
        "period": request.period.dict(),
        "parameters": request.parameters.dict(),
        "data": mock_data,
        "legend": legend,
        "data_source": "mock"
    }


@app.get("/api/presets")
async def get_presets():
    """
    Retourne les presets agricoles disponibles.
    """
    return {
        "presets": [
            {
                "id": "post_semis_ete",
                "name": "Post-semis √©t√©",
                "start_date": "2024-04-15",
                "end_date": "2024-06-30"
            },
            {
                "id": "interculture_ete",
                "name": "Interculture √©t√©",
                "start_date": "2024-07-01",
                "end_date": "2024-09-15"
            },
            {
                "id": "interculture_hiver",
                "name": "Interculture hiver",
                "start_date": "2024-09-16",
                "end_date": "2024-11-30"
            },
            {
                "id": "semis_ble",
                "name": "Semis bl√©",
                "start_date": "2024-10-01",
                "end_date": "2024-11-15"
            }
        ]
    }


@app.get("/api/years")
async def get_available_years():
    """
    Retourne les ann√©es disponibles pour les projections.
    """
    return {
        "years": [2020, 2030, 2040, 2050],
        "current": 2020
    }


@app.get("/api/variables")
async def get_available_variables():
    """
    Retourne la liste des variables climatiques disponibles.
    """
    variables = [
        {
            "code": var.code.value,
            "name": var.name,
            "unit": var.unit,
            "description": var.description
        }
        for var in VARIABLES_INFO.values()
    ]
    return {"variables": variables}


@app.get("/api/experiments")
async def get_available_experiments():
    """
    Retourne la liste des sc√©narios climatiques disponibles.
    """
    experiment_names = {
        ExperimentType.HISTORICAL: "Donn√©es historiques",
        ExperimentType.SSP126: "SSP1-2.6 (Sc√©nario optimiste)",
        ExperimentType.SSP245: "SSP2-4.5 (Sc√©nario interm√©diaire)",
        ExperimentType.SSP370: "SSP3-7.0 (Sc√©nario pessimiste)",
        ExperimentType.SSP585: "SSP5-8.5 (Sc√©nario tr√®s pessimiste)"
    }
    
    experiments = [
        {"code": exp.value, "name": experiment_names.get(exp, exp.value)}
        for exp in ExperimentType
    ]
    return {"experiments": experiments}


@app.get("/api/datasets")
async def get_available_datasets(
    variable: Optional[str] = None,
    experiment: Optional[str] = None,
    start_year: Optional[int] = None,
    end_year: Optional[int] = None
):
    """
    Retourne la liste des jeux de donn√©es disponibles avec filtres optionnels.
    
    Param√®tres:
    - variable: Filtrer par variable (ex: "pr", "tas")
    - experiment: Filtrer par sc√©nario (ex: "ssp370", "historical")
    - start_year: Ann√©e de d√©but de la p√©riode
    - end_year: Ann√©e de fin de la p√©riode
    """
    datasets = AVAILABLE_DATASETS.copy()
    
    if variable:
        try:
            var_type = VariableType(variable)
            datasets = get_datasets_for_variables([var_type])
        except ValueError:
            return {"error": f"Variable '{variable}' non reconnue"}
    
    if experiment:
        try:
            exp_type = ExperimentType(experiment)
            datasets = [ds for ds in datasets if exp_type in ds.experiment]
        except ValueError:
            return {"error": f"Sc√©nario '{experiment}' non reconnu"}
    
    if start_year and end_year:
        datasets = [ds for ds in datasets 
                   if ds.period_start <= start_year and ds.period_end >= end_year]
    
    return {
        "datasets": [
            {
                "gcm": ds.gcm.value,
                "rcm": ds.rcm.value,
                "experiments": [e.value for e in ds.experiment],
                "variables": [v.value for v in ds.variables],
                "resolution": ds.resolution,
                "period": f"{ds.period_start}-{ds.period_end}",
                "frequency": ds.frequency,
                "member": ds.member,
                "downscaling_method": ds.downscaling_method.value
            }
            for ds in datasets
        ],
        "count": len(datasets)
    }


@app.get("/api/datasets/summary")
async def get_datasets_summary():
    """
    Retourne un r√©sum√© des donn√©es disponibles.
    """
    total_datasets = len(AVAILABLE_DATASETS)
    variables_available = set()
    experiments_available = set()
    resolutions_available = set()
    
    for ds in AVAILABLE_DATASETS:
        variables_available.update([v.value for v in ds.variables])
        experiments_available.update([e.value for e in ds.experiment])
        resolutions_available.add(ds.resolution)
    
    return {
        "total_datasets": total_datasets,
        "variables_count": len(variables_available),
        "variables": sorted(list(variables_available)),
        "experiments_count": len(experiments_available),
        "experiments": sorted(list(experiments_available)),
        "resolutions": sorted(list(resolutions_available)),
        "data_url": "https://console.object.files.data.gouv.fr/browser/meteofrance-drias/SocleM-Climat-2025%2F",
        "documentation_url": "https://guides.data.gouv.fr/guide-du-participant-au-hackathon-le-climat-en-donnees/ressources-du-hackathon/donnees/donnees-de-projections-climatiques"
    }

